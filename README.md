# VOICE-assitant
1)Abstract
In the modern era of fast moving technology we can do things which we never thought we could do before but, now because new advancement we got platform to work on build those that we have only seen in movies personal voice assistant which has ability to interact with us and do our task with ease and comfort , Now a day’s we see many voice assistant application like Microsoft Cortana, Siri for mac ,etc. which helps us a lot to complete our tasks using voice communication or voice commands  these Application mostly works with Internet Connections. Our application is named as JASON with Voice Recognition Intelligence, which takes the user input in form of voice or text and process it and returns the output in various forms like action to be performed or the search result is dictated to the end user. In addition, this proposed system can change the way of interactions between end user and the computer. 


2)Literature Reviews/Comparative study

Speech recognition has a long history with several waves of major innovations. Speech recognition for dictation, search, and voice commands has become a standard feature on windows and wearable devices. Design of a compact large vocabulary speech recognition system that can run efficiently on computers, accurately and with low latency.  This is achieved by using a CTC based LSTM acoustic model which predicts context independent computer and is compressed to a tenth of its original size using a combination of SVD-based compression and quantization. Quantized deep neural networks (DNNs) and on-the-fly language model rescoring to achieve real-time performance on modern computers. The ASR and Search components perform speech recognition and search tasks. In addition to ASR and Search, we also integrate a query parsing module between ASR and Search for a number of reasons. Voice search is implemented as a two stage search procedure where string candidates generated by an automatic speech recognition (ASR) system are re-scored in order to identify the best matching entry from a potentially very large application specific database. Study provides a good example of how additional domain specific knowledge sources can be used with a domain independent ASR system to facilitate voice access to online search indices and offline search.

3)Problem Formulation
We are all well aware about Microsoft Cortana, Apple’s Siri for mac, Google Assistant for Chromebook and many other virtual assistants which are designed to aid the tasks of users in Windows platforms.
The resultant software Jason will be more secure and reliable than the currently available ones it works online with endless features also features that you can add by yourself.


4)Tools used for Implementation

System requirements:
Python 3.3+
Spyder IDE
Windows (any version)
Install all these python libraries:
pip install pypiwin32.
pip install SpeechRecognition
pip install beautifulsoup4
pip install vlc
pip install youtube-dl
pip install pyowm
pip install wikipedia

Hardware requirements:

100mb storage
4gb ram
Intel i3 (any generation)
Or ryzen(any generation)
Graphics not needed



6)Merits of Proposed system 
1-Accessibility Options for Mobility and the Visually Impaired
For those with mobility restrictions or the visually impaired, speech recognition has always been a big help, extending the accessibility of computer-based technologies to a much wider audience.
The proliferation of voice-responsive virtual assistants, capable of engaging with users in conversational language, has been a significant step forward. So, too, is the continuing integration of hardware, tools, and consumer goods with Internet of Things (IoT) technology and cloud resources.
2-Co-ordination of IoT Devices
For the consumer market, the expansion of IoT has created entire new generations of (to varying degrees) smart objects, appliances, and accessories. Some are too tiny to even feature buttons, much less screens or keyboards. Others are designed to do jobs that don’t require manual activation or guidance.
Speech recognition is a practical and logical option which can enable users to control such objects from a distance, often via a connected virtual assistant device.
3-Adding Personality to Virtual Shopping
Convenience is undoubtedly the primary driving factor behind the rise of ecommerce. However, the sector has yet to figure out a way to make up for the lack of personal interaction consumers experience when selecting goods, asking questions, or making purchases. People naturally like to engage with a flesh and blood assistant or customer service agent at some point in the buying process.
Once again, AI is coming to the rescue – this time, in the form of virtual shopping assistants. The AI-powered shopping assistant learns about your tastes and interests while shopping online, and then uses this data to inform you about products you might like to purchase, creating a virtual experience that’s more like shopping in a virtual store.
Just as speech recognition has come a long way, natural voice technologies (which are typically modelled on recordings of the vocal patterns of real people) have made harsh, robotic-sounding voices the exception rather than the norm. The result is virtual assistants fielding queries on high-end commercial websites becoming increasingly indistinguishable from human beings.
4-Reducing Our Dependence on Screens
When it was first introduced at consumer level, speech recognition was said to herald the death of the keyboard – but the technology at the time just wasn’t good enough.
However, today’s more advanced recognition algorithms do make the technology a viable alternative to hardware-based input devices like keyboards or touchscreens.
An interesting side effect of this is that speech recognition with interactive voice assistants can help reduce our dependence on screens – an obsession that’s become potentially unhealthy and of concern to any parent of a teenager with a tablet or laptops.
5-A Reluctance to Comprehend
There’s a line from an old Sci-Fi series on television, where one of the main characters says, “She understands. She doesn’t comprehend.”
This fine distinction speaks to one of the biggest limitations of current speech recognition technology and the responses coded into the personalities of virtual assistants.
On the recognition side, there’s a delay when first using a system as it accustoms itself to your unique speech patterns. This might be anywhere from a few seconds to a few hours (or even days), depending on the sophistication of the underlying software, the capabilities of your hardware, and the strength and speed of your internet connection.
Recognition performance should improve over time. However, this is still dependent on those underlying factors.
6-An Inability to Hear
Reports suggest that there will be somewhere in the region of 24 billion IoT connected devices around the globe by 2020 – that’s about four devices each for every person on the planet. The concern is that all the wearable gadgets, smart consumer appliances, intelligent vehicles and connected infrastructure will cause localized pools of interference, and a continuous struggle for bandwidth.
Factors like this may have a negative impact on the ability of speech recognition systems to access their databases and perform their primary function.
Another impediment which can be demonstrated in the here and now is the effect of extraneous noise on voice-activated systems. With the current state of technology, it’s not uncommon for the speech recognition system powering a smart home to pay equal attention to the people on the TV or radio as it does to the owner of the house.
7-Dumbing Down Offline
Smartphone users and Desktop users who’ve become accustomed to the speech recognition functionality of OK, Google on the Android platform, or Apple’s Siri, Cortana on windows will know that a fast and stable internet connection is essential to the operation of these virtual assistants.
Offline recognition generally isn’t considered a necessity in the design of these systems. Any support for it is usually bolted on as an afterthought and involves the downloading of an immense recognition file to the user’s device.
Given that fast, stable internet isn’t as common around the world as many developers might assume, this effectively excludes speech recognition and virtual assistants as viable options in many parts of the globe.
8-A Lack of Initiative
Finally, there are the issues of intelligence and initiative. Though much has been made of the potential of AI, adaptive learning, and prescriptive/predictive analytics in powering virtual assistants, the practical applications have yet to truly manifest.
For the moment, virtual assistants are largely responsive – sitting silent (or occasionally piping up with a pre-programmed conversational gambit) until the user issues a fresh command or query.
Though there’s a fine line to be drawn between making a system intrusive and having it behave in an advisory capacity based on past observations and incoming data, there’s certainly room for the next generation of virtual assistants to display more initiative if the technology is to truly become an integral part of domestic and business life.







7)Architecture Diagram for proposed method




 

8)Implementation and Description of Project Modules

Module 1-
pyttsx3 is a text-to-speech conversion library in Python. Unlike alternative libraries, it works offline, and is compatible with both Python 2 and 3.
You can install it easily via the following command.
pip install pyttsx3Python module
First, clone the repository from the official GitHub site, and unzip it to a directory of your choice.
Then, open up a command line, and activate the virtual environment you prefer. Once you’re done, change the directory to the root of the master folder. It should have a file called setup.py. Run the following command:
python setup.py install
Once the installation has completed, kindly check if you have the following module:
pip show pyttsx3
If you’re using Windows, you need to verify the pypiwin32 module as well.
pip show  pypiwin32
Kindly install it using the following command if the module is not present:
pip install  pypiwin32
Text to speech
The text-to-speech features for this module are based on languages installed in your operating system.
By default, it should come together with the language pack during the installation of the operating system. You need to install the language pack manually if you intend to use other languages.

How to install
1. Setup
The proper way to install this module is by cloning the repository and installing via the setup Python file.
This is mainly because the published version in PyPI isn’t the latest version at the time of this writing. You can do a pip install in the future if it the developer has published the latest version on PyPi. EDIT: The package has been updated as of July 2020. You can install it easily via the following command.
 

Python module
First, clone the repository from the official GitHub site, and unzip it to a directory of your choice.
Then, open up a command line, and activate the virtual environment you prefer. Once you’re done, change the directory to the root of the master folder. It should have a file called setup.py. Run the following command:
 

Once the installation has completed, kindly check if you have the following module:
 
If you’re using Windows, you need to verify the pypiwin32 module as well.
 
Kindly install it using the following command if the module is not present:
 
Text to speech
The text-to-speech features for this module are based on languages installed in your operating system.
By default, it should come together with the language pack during the installation of the operating system. You need to install the language pack manually if you intend to use other languages.
For Windows user, head over to the Language setting. You should be able to see the following user interface.
Import
Let’s start with a simple import statement

import pyttsx3
Initialization
The initialization is pretty straightforward — you can just type the following code:

engine = pyttsx3.init()
If you encountered errors related to a missing driver, you can try to pass in the driver’s name. There are four available built-in drivers:
•	dummy.py — Test driver that does nothing. You can use the structure as reference to implement your own driver.
•	espeak.py — Driver for other platforms, such as Ubuntu
•	nsss.py — Driver for MacOS
•	sapi5.py — Driver for Windows operating system
Example for initialization with the driver’s name is as follows:
engine = pyttsx3.init("sapi5")
Text to speech
Let’s try out the following code to say something simple. Save it in a Python file, and run it.

import pyttsx3
engine = pyttsx3.init()engine.say('Welcome sir')
engine.runAndWait()

You should be able to hear the voice say, “Welcome  sir “

Module 2-
Microsoft Speech API (SAPI) 5.3
Microsoft Speech API 5.3

Microsoft Speech API (SAPI) 5.3
This is the documentation for Microsoft Speech API (SAPI) 5.3, the native API for Windows.

These are interfaces, structures, and enumerations that have been added for the SAPI 5.3 release:

New SAPI 5.3 Interfaces
New SAPI 5.3 Enumerations
New SAPI 5.3 Structures
This topic also includes conceptual material that describes and explains the new scenarios that SAPI 5.3 supports:

W3C Speech Synthesis Mark-up Language
W3C Speech Recognition Grammar Specification
Semantic Interpretation
New Managed API for Speech
Windows Vista includes a new .NET namespace, System. Speech, that allows developers to speech-enable applications, especially those based on the Windows Presentation Foundation. Authors of managed applications can use this in addition to, or as an alternative to SAPI. For more information, see the System.Speech.* namespaces in the Windows SDK Class Library. They are:
